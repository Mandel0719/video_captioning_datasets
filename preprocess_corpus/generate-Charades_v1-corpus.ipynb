{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate corpus and gruond-truth references of released videos\n",
    "\n",
    "### Corpus file contents\n",
    "0. train_data: captions and idxs of training videos in format [corpus_widxs, vidxs, corpus_pidxs], where:\n",
    "    - corpus_widxs is a list of lists with the index of words in the vocabulary\n",
    "    - vidxs is a list of indexes of video features in the features file\n",
    "    - corpus_pidxs is a list of lists with the index of POS tags in the POS tagging vocabulary\n",
    "1. val_data: same format of train_data.\n",
    "2. test_data: same format of train_data.\n",
    "3. vocabulary: in format {'word': count}.\n",
    "4. idx2word: is the vocabulary in format {idx: 'word'}.\n",
    "5. word_embeddings: are the vectors of each word. The i-th row is the word vector of the i-th word in the vocabulary.\n",
    "6. idx2pos: is the vocabulary of POS tagging in format {idx: 'POSTAG'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate split for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>scene</th>\n",
       "      <th>quality</th>\n",
       "      <th>relevance</th>\n",
       "      <th>verified</th>\n",
       "      <th>script</th>\n",
       "      <th>objects</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>actions</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46GP8</td>\n",
       "      <td>HR43</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A person cooking on a stove while watching som...</td>\n",
       "      <td>food;stove;window</td>\n",
       "      <td>A person cooks food on a stove before looking ...</td>\n",
       "      <td>c092 11.90 21.20;c147 0.00 12.60</td>\n",
       "      <td>24.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N11GT</td>\n",
       "      <td>0KZ7</td>\n",
       "      <td>Stairs</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One person opens up a folded blanket, then sne...</td>\n",
       "      <td>blanket;broom;floor</td>\n",
       "      <td>Person at the bottom of the staircase shakes a...</td>\n",
       "      <td>c098 8.60 14.20;c075 0.00 11.70;c127 0.00 15.2...</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0IH69</td>\n",
       "      <td>6RE8</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A person is seen leaving a cabinet. They then ...</td>\n",
       "      <td>book;box;cabinet;shelf</td>\n",
       "      <td>A person is standing in a bedroom. They walk o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KRF68</td>\n",
       "      <td>YA10</td>\n",
       "      <td>Laundry room</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A person runs into their laundry room. They gr...</td>\n",
       "      <td>clothes;door;phone</td>\n",
       "      <td>A person runs in and shuts door. The person gr...</td>\n",
       "      <td>c018 22.60 27.80;c141 4.10 9.60;c148 10.30 25....</td>\n",
       "      <td>30.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MJO7C</td>\n",
       "      <td>6RE8</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A person runs into their pantry holding a bott...</td>\n",
       "      <td>cup;phone</td>\n",
       "      <td>A person runs in place while holding a bottle ...</td>\n",
       "      <td>c015 0.00 32.00;c107 0.00 32.00</td>\n",
       "      <td>31.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>7K2CS</td>\n",
       "      <td>HJZQ</td>\n",
       "      <td>Garage</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Person enters the garage while sneezing. Perso...</td>\n",
       "      <td>chair;clothes;door;food;sandwich;shirt;spoon</td>\n",
       "      <td>A enters through a doorway, sneezes, then clos...</td>\n",
       "      <td>c065 17.60 31.00;c067 17.60 31.00;c153 0.00 5....</td>\n",
       "      <td>30.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>S2A89</td>\n",
       "      <td>KL48</td>\n",
       "      <td>Bathroom</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A person takes a chair and walks it over, plac...</td>\n",
       "      <td>chair;door</td>\n",
       "      <td>A PERSON IS TAKING A CHAIR FROM ONE ROOM TO TH...</td>\n",
       "      <td>c006 4.00 10.80;c141 4.40 10.90;c151 12.80 20....</td>\n",
       "      <td>19.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>01O27</td>\n",
       "      <td>18IT</td>\n",
       "      <td>Bathroom</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A person enters a bathroom and closes the door...</td>\n",
       "      <td>door;floor;mirror</td>\n",
       "      <td>A person is walking towards the bathroom. A pe...</td>\n",
       "      <td>c006 5.10 11.50;c008 0.50 6.60;c124 39.00 47.0...</td>\n",
       "      <td>46.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>2MJ72</td>\n",
       "      <td>6RE8</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A person opens a window in their laundry room....</td>\n",
       "      <td>door;towel;window</td>\n",
       "      <td>A person opens a window and looks out of it.  ...</td>\n",
       "      <td>c006 11.00 17.00;c037 20.70 31.00;c092 0.60 8....</td>\n",
       "      <td>30.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>PG1ID</td>\n",
       "      <td>D0RU</td>\n",
       "      <td>Home Office / Study (A room in a house used fo...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A person snuggles with a laptop, A person sits...</td>\n",
       "      <td>broom;laptop;something</td>\n",
       "      <td>{}</td>\n",
       "      <td>c047 0.00 33.00;c051 0.00 33.00;c052 0.00 33.0...</td>\n",
       "      <td>32.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7985 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id subject                                              scene  \\\n",
       "0     46GP8    HR43                                            Kitchen   \n",
       "1     N11GT    0KZ7                                             Stairs   \n",
       "2     0IH69    6RE8                                            Bedroom   \n",
       "3     KRF68    YA10                                       Laundry room   \n",
       "4     MJO7C    6RE8                                            Kitchen   \n",
       "...     ...     ...                                                ...   \n",
       "7980  7K2CS    HJZQ                                             Garage   \n",
       "7981  S2A89    KL48                                           Bathroom   \n",
       "7982  01O27    18IT                                           Bathroom   \n",
       "7983  2MJ72    6RE8                                            Bedroom   \n",
       "7984  PG1ID    D0RU  Home Office / Study (A room in a house used fo...   \n",
       "\n",
       "      quality  relevance verified  \\\n",
       "0         6.0        7.0      Yes   \n",
       "1         6.0        7.0      Yes   \n",
       "2         6.0        5.0      Yes   \n",
       "3         6.0        7.0      Yes   \n",
       "4         6.0        6.0      Yes   \n",
       "...       ...        ...      ...   \n",
       "7980      6.0        6.0      Yes   \n",
       "7981      7.0        7.0      Yes   \n",
       "7982      6.0        7.0      Yes   \n",
       "7983      6.0        6.0      Yes   \n",
       "7984      6.0        6.0      Yes   \n",
       "\n",
       "                                                 script  \\\n",
       "0     A person cooking on a stove while watching som...   \n",
       "1     One person opens up a folded blanket, then sne...   \n",
       "2     A person is seen leaving a cabinet. They then ...   \n",
       "3     A person runs into their laundry room. They gr...   \n",
       "4     A person runs into their pantry holding a bott...   \n",
       "...                                                 ...   \n",
       "7980  Person enters the garage while sneezing. Perso...   \n",
       "7981  A person takes a chair and walks it over, plac...   \n",
       "7982  A person enters a bathroom and closes the door...   \n",
       "7983  A person opens a window in their laundry room....   \n",
       "7984  A person snuggles with a laptop, A person sits...   \n",
       "\n",
       "                                           objects  \\\n",
       "0                                food;stove;window   \n",
       "1                              blanket;broom;floor   \n",
       "2                           book;box;cabinet;shelf   \n",
       "3                               clothes;door;phone   \n",
       "4                                        cup;phone   \n",
       "...                                            ...   \n",
       "7980  chair;clothes;door;food;sandwich;shirt;spoon   \n",
       "7981                                    chair;door   \n",
       "7982                             door;floor;mirror   \n",
       "7983                             door;towel;window   \n",
       "7984                        broom;laptop;something   \n",
       "\n",
       "                                           descriptions  \\\n",
       "0     A person cooks food on a stove before looking ...   \n",
       "1     Person at the bottom of the staircase shakes a...   \n",
       "2     A person is standing in a bedroom. They walk o...   \n",
       "3     A person runs in and shuts door. The person gr...   \n",
       "4     A person runs in place while holding a bottle ...   \n",
       "...                                                 ...   \n",
       "7980  A enters through a doorway, sneezes, then clos...   \n",
       "7981  A PERSON IS TAKING A CHAIR FROM ONE ROOM TO TH...   \n",
       "7982  A person is walking towards the bathroom. A pe...   \n",
       "7983  A person opens a window and looks out of it.  ...   \n",
       "7984                                                 {}   \n",
       "\n",
       "                                                actions  length  \n",
       "0                      c092 11.90 21.20;c147 0.00 12.60   24.83  \n",
       "1     c098 8.60 14.20;c075 0.00 11.70;c127 0.00 15.2...   18.33  \n",
       "2                                                   NaN   30.25  \n",
       "3     c018 22.60 27.80;c141 4.10 9.60;c148 10.30 25....   30.33  \n",
       "4                       c015 0.00 32.00;c107 0.00 32.00   31.38  \n",
       "...                                                 ...     ...  \n",
       "7980  c065 17.60 31.00;c067 17.60 31.00;c153 0.00 5....   30.08  \n",
       "7981  c006 4.00 10.80;c141 4.40 10.90;c151 12.80 20....   19.29  \n",
       "7982  c006 5.10 11.50;c008 0.50 6.60;c124 39.00 47.0...   46.08  \n",
       "7983  c006 11.00 17.00;c037 20.70 31.00;c092 0.60 8....   30.25  \n",
       "7984  c047 0.00 33.00;c051 0.00 33.00;c052 0.00 33.0...   32.08  \n",
       "\n",
       "[7985 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('../../../data/Charades/annotations/Charades_v1_train.csv', ',')  \n",
    "valid_data = pd.read_csv('../../../data/Charades/annotations/Charades_v1_test.csv', ',')  \n",
    "# test_data = pd.read_csv('../../../data/Charades/annotations/Charades_v1_test.csv', ',')\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vidxs, train_corpus = [], []\n",
    "for vid, script, descriptions in zip(train_data['id'], train_data['script'], train_data['descriptions']):\n",
    "    train_vidxs.append(vid)\n",
    "    train_corpus.append(script)\n",
    "    for d in descriptions.split(';'):\n",
    "        train_vidxs.append(vid)\n",
    "        train_corpus.append(d)\n",
    "# train_vidxs, train_corpus = list(train_data['id']), list(train_data['descriptions'])\n",
    "# valid_vidxs, valid_corpus = list(valid_data['id']), list(valid_data['descriptions'])\n",
    "# test_vidxs, test_corpus = list(test_data['video-id']), list(test_data['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "wordvectors = {}\n",
    "# with open('./glove.42B.300d.txt') as f:\n",
    "with open('./glove.6B.300d.txt') as f:\n",
    "    for line in f:\n",
    "        s = line.strip().split(' ')\n",
    "        if len(s) == 301:\n",
    "            wordvectors[s[0]] = np.array(s[1:], dtype=float)\n",
    "    print(len(wordvectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the vocabulary from train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jeperez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. count of words per caption: 23.913934007559504\n",
      "Count of unique words:  4010\n",
      "missing word: shoes.this\n",
      "missing word: floor/bed\n",
      "missing word: rinces\n",
      "missing word: shelf.the\n",
      "missing word: .the\n",
      "missing word: selfies\n",
      "missing word: up.the\n",
      "missing word: papers.the\n",
      "missing word: towel.the\n",
      "missing word: bedroom.they\n",
      "missing word: table/desk\n",
      "missing word: manac\n",
      "missing word: something..\n",
      "missing word: begings\n",
      "missing word: stiring\n",
      "missing word: bedroom.the\n",
      "missing word: doorwa\n",
      "missing word: food.the\n",
      "missing word: tidys\n",
      "missing word: bed.the\n",
      "missing word: bench.the\n",
      "missing word: stand.the\n",
      "missing word: selfie\n",
      "missing word: mid-stairs\n",
      "missing word: place.another\n",
      "missing word: thews\n",
      "missing word: cookie..\n",
      "missing word: picture/video\n",
      "missing word: cup.the\n",
      "missing word: brooming\n",
      "missing word: decines\n",
      "missing word: stairway.the\n",
      "missing word: dreser\n",
      "missing word: pillor\n",
      "missing word: bowelslk\n",
      "missing word: proccess\n",
      "missing word: lieing\n",
      "missing word: jar.the\n",
      "missing word: neaten\n",
      "missing word: vauuming\n",
      "missing word: scring\n",
      "missing word: apicture\n",
      "missing word: .proceeds\n",
      "missing word: pack.the\n",
      "missing word: chair.the\n",
      "missing word: walksinto\n",
      "missing word: blanlet\n",
      "missing word: cradleing\n",
      "missing word: them-self\n",
      "missing word: thorwing\n",
      "missing word: closey\n",
      "missing word: half-eaten\n",
      "missing word: stovr\n",
      "missing word: stove.the\n",
      "missing word: self.the\n",
      "missing word: laughs.the\n",
      "missing word: door.the\n",
      "missing word: unlaces\n",
      "missing word: water.another\n",
      "missing word: tehy\n",
      "missing word: mirrow\n",
      "missing word: mirrir\n",
      "missing word: frig\n",
      "missing word: .than\n",
      "missing word: adesk\n",
      "missing word: sawich\n",
      "missing word: homework.they\n",
      "missing word: holding..\n",
      "missing word: sandwhich\n",
      "missing word: coffe\n",
      "missing word: clotes\n",
      "missing word: box.the\n",
      "missing word: trowing\n",
      "missing word: floor.the\n",
      "missing word: doorwaywhile\n",
      "missing word: shelves.the\n",
      "missing word: times.the\n",
      "missing word: walked/stomped\n",
      "missing word: cooking.the\n",
      "missing word: visable\n",
      "missing word: floor.another\n",
      "missing word: shoe.the\n",
      "missing word: bpacket\n",
      "missing word: clothes.the\n",
      "missing word: shoe.and\n",
      "missing word: puring\n",
      "missing word: them.the\n",
      "missing word: pop.the\n",
      "missing word: theu\n",
      "missing word: deside\n",
      "missing word: mirror.the\n",
      "missing word: camera.the\n",
      "missing word: pisce\n",
      "missing word: it.get\n",
      "missing word: pepto-bismol\n",
      "missing word: drity\n",
      "missing word: refridgerator\n",
      "missing word: face.another\n",
      "missing word: bowl.the\n",
      "missing word: hair.another\n",
      "missing word: scraching\n",
      "missing word: person.both\n",
      "missing word: desk.the\n",
      "missing word: stand.proceeds\n",
      "missing word: feet.proceeds\n",
      "missing word: perso\n",
      "missing word: undresing\n",
      "missing word: selfies.the\n",
      "missing word: persno\n",
      "missing word: couch..\n",
      "missing word: picka\n",
      "missing word: quiddith\n",
      "missing word: a+\n",
      "missing word: nteracting\n",
      "missing word: work/play\n",
      "missing word: peson\n",
      "missing word: table.the\n",
      "missing word: cleaning/organizing\n",
      "missing word: etelevision\n",
      "missing word: purs\n",
      "missing word: lokks\n",
      "missing word: .another\n",
      "missing word: warching\n",
      "missing word: pollow\n",
      "missing word: unscrews\n",
      "missing word: casually-dressed\n",
      "missing word: doorknow\n",
      "missing word: dorrway\n",
      "missing word: clohtes\n",
      "missing word: scarf.the\n",
      "missing word: light..\n",
      "missing word: cabitnet\n",
      "missing word: pillow.the\n",
      "missing word: sneezing.the\n",
      "missing word: talbe\n",
      "missing word: outside/\n",
      "missing word: reseals\n",
      "missing word: laungh\n",
      "missing word: cabit\n",
      "missing word: attiac\n",
      "missing word: bucket/trash\n",
      "missing word: teddybear\n",
      "missing word: pole.the\n",
      "missing word: hand.the\n",
      "missing word: dolding\n",
      "missing word: laaptop\n",
      "missing word: mashine\n",
      "missing word: side.the\n",
      "missing word: vegin\n",
      "missing word: begans\n",
      "missing word: tv.the\n",
      "missing word: drink.the\n",
      "missing word: refrigerator.the\n",
      "missing word: sink.the\n",
      "missing word: cloth.another\n",
      "missing word: bathrom\n",
      "missing word: mirroe\n",
      "missing word: stadning\n",
      "missing word: .a\n",
      "missing word: hands.another\n",
      "missing word: pilow\n",
      "missing word: top.he\n",
      "missing word: refrigarator\n",
      "missing word: grapsing\n",
      "missing word: phone.the\n",
      "missing word: efloor\n",
      "missing word: edoorknob\n",
      "missing word: backpack/bag\n",
      "missing word: hall.the\n",
      "missing word: andthen\n",
      "missing word: palced\n",
      "missing word: smiliing\n",
      "missing word: broom.the\n",
      "missing word: sittiing\n",
      "missing word: personlaying\n",
      "missing word: hoding\n",
      "missing word: brrom\n",
      "missing word: unlace\n",
      "missing word: humerous\n",
      "missing word: gabs\n",
      "missing word: ..\n",
      "missing word: beging\n",
      "missing word: aroudn\n",
      "missing word: grabbin\n",
      "missing word: sleep.the\n",
      "missing word: writting\n",
      "missing word: vigourous\n",
      "missing word: on.the\n",
      "missing word: sofa/couch\n",
      "missing word: inot\n",
      "missing word: gymbag\n",
      "missing word: spatuala\n",
      "missing word: out..\n",
      "missing word: bathtub/shower\n",
      "missing word: something.the\n",
      "missing word: totake\n",
      "missing word: fold-up\n",
      "missing word: table-weight\n",
      "missing word: mub\n",
      "missing word: overshirt\n",
      "missing word: auxilliary\n",
      "missing word: laptop.the\n",
      "missing word: vacumming\n",
      "missing word: procedes\n",
      "missing word: shef\n",
      "missing word: camera-man\n",
      "missing word: headbanged\n",
      "missing word: driking\n",
      "missing word: opend\n",
      "missing word: wips\n",
      "missing word: box.another\n",
      "missing word: sandwich.the\n",
      "missing word: lint-trap\n",
      "missing word: toilet.the\n",
      "missing word: gargles\n",
      "missing word: theirselves\n",
      "missing word: .turns\n",
      "missing word: there.the\n",
      "missing word: camera/typing\n",
      "missing word: room/man\n",
      "missing word: persin\n",
      "missing word: counter.the\n",
      "missing word: ggling\n",
      "missing word: mouth.the\n",
      "missing word: someithing\n",
      "missing word: out.the\n",
      "missing word: vacum\n",
      "missing word: towl\n",
      "missing word: laughing.the\n",
      "missing word: theirself\n",
      "missing word: chair.removed\n",
      "missing word: cabined\n",
      "missing word: rgroceries\n",
      "missing word: elaptop\n",
      "missing word: itand\n",
      "missing word: apple.the\n",
      "missing word: papers/book\n",
      "missing word: office/study\n",
      "missing word: peice\n",
      "missing word: rag/paper\n",
      "missing word: laudry\n",
      "missing word: carrys\n",
      "missing word: closses\n",
      "missing word: vaccuming\n",
      "missing word: recloses\n",
      "missing word: table..\n",
      "missing word: caot\n",
      "missing word: container.the\n",
      "missing word: irror\n",
      "missing word: vaccums\n",
      "missing word: relocks\n",
      "missing word: carboard\n",
      "missing word: benst\n",
      "missing word: vegins\n",
      "missing word: back.the\n",
      "missing word: latptop\n",
      "missing word: it..\n",
      "missing word: water/coffee\n",
      "missing word: lamp.the\n",
      "missing word: leaes/\n",
      "missing word: refection\n",
      "missing word: peoople\n",
      "missing word: one.0\n",
      "missing word: refrierator\n",
      "missing word: wingow\n",
      "missing word: excersise\n",
      "missing word: bed..\n",
      "missing word: whicks\n",
      "missing word: homeowrk\n",
      "missing word: rsomething\n",
      "missing word: sofasofa\n",
      "missing word: anti-acids\n",
      "missing word: wardrove\n",
      "missing word: stair.the\n",
      "missing word: checls\n",
      "missing word: holdinga\n",
      "missing word: tiyding\n",
      "missing word: themselve\n",
      "missing word: light.the\n",
      "missing word: ishoes\n",
      "missing word: lookng\n",
      "missing word: reading.the\n",
      "missing word: themsevels\n",
      "missing word: washer/dryer\n",
      "missing word: aperson\n",
      "missing word: chiar\n",
      "missing word: aroom\n",
      "missing word: refrigator\n",
      "missing word: catchesit\n",
      "missing word: blanket.the\n",
      "missing word: straigtens\n",
      "missing word: atable\n",
      "missing word: chair.sat\n",
      "missing word: computer.the\n",
      "missing word: tking\n",
      "missing word: hteir\n",
      "missing word: drinkl\n",
      "missing word: -door\n",
      "missing word: .one\n",
      "missing word: grins.the\n",
      "missing word: theyr\n",
      "missing word: loooks\n",
      "missing word: jacketand\n",
      "missing word: cookingon\n",
      "missing word: salt.the\n",
      "missing word: vaccuums\n",
      "missing word: moves.they\n",
      "missing word: window.and\n",
      "missing word: steps.the\n",
      "missing word: pillow/\n",
      "missing word: medicine.the\n",
      "missing word: package.the\n",
      "missing word: appropriatley\n",
      "missing word: processds\n",
      "missing word: doorway.the\n",
      "missing word: hair.the\n",
      "missing word: desk/\n",
      "missing word: on/inspecting\n",
      "missing word: intot\n",
      "missing word: work.the\n",
      "missing word: walksin\n",
      "missing word: doornobo\n",
      "missing word: sink.sink\n",
      "missing word: moves/organizes\n",
      "missing word: dishes/containers\n",
      "missing word: erson\n",
      "missing word: enterway\n",
      "missing word: anotherperson\n",
      "missing word: bathroo\n",
      "missing word: blanket/pillow\n",
      "missing word: sinktop\n",
      "missing word: homework/notes\n",
      "missing word: stting\n",
      "missing word: sandwitch\n",
      "missing word: sofa.the\n",
      "missing word: room.the\n",
      "missing word: refridgarator\n",
      "missing word: vacuming\n",
      "missing word: stairs.another\n",
      "missing word: blancket\n",
      "missing word: lid.the\n",
      "missing word: room.one\n",
      "missing word: phone..\n",
      "missing word: .takes\n",
      "missing word: andholding\n",
      "missing word: 'drink\n",
      "missing word: hands.tips\n",
      "missing word: inters\n",
      "missing word: pages.the\n",
      "missing word: bottle.the\n",
      "missing word: bottle.another\n",
      "missing word: vabinet\n",
      "missing word: isdrinking\n",
      "missing word: book.the\n",
      "missing word: couch.the\n",
      "missing word: doow\n",
      "missing word: getts\n",
      "missing word: layind\n",
      "missing word: cupboard/shelf\n",
      "missing word: down.the\n",
      "missing word: videoing\n",
      "missing word: types/works\n",
      "missing word: door.a\n",
      "missing word: picutre\n",
      "missing word: pciks\n",
      "missing word: open/close\n",
      "missing word: paper.the\n",
      "missing word: picture.the\n",
      "missing word: off.the\n",
      "missing word: skillet/pot/pan\n",
      "missing word: thens\n",
      "missing word: spide\n",
      "missing word: wayer\n",
      "missing word: shelf.another\n",
      "missing word: drinkink\n",
      "missing word: vaccumming\n",
      "missing word: sneeeze\n",
      "missing word: cloth.the\n",
      "missing word: closesing\n",
      "missing word: place.the\n",
      "missing word: door.another\n",
      "missing word: cleaning.one\n",
      "missing word: bathrooom\n",
      "missing word: bottem\n",
      "missing word: handle.the\n",
      "missing word: skillet.the\n",
      "missing word: walkins\n",
      "missing word: forward.the\n",
      "missing word: istting\n",
      "missing word: seconds.the\n",
      "missing word: smiling.the\n",
      "missing word: snaekers\n",
      "missing word: coatrack\n",
      "missing word: outside..\n",
      "missing word: machine.the\n",
      "missing word: bedroom/hallway\n",
      "missing word: around..\n",
      "missing word: school/work/professional\n",
      "missing word: unbuttons\n",
      "missing word: someone.the\n",
      "missing word: toilet/powder\n",
      "count of missing words:  401\n",
      "3609 3611 3611\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "vocab, total_len = {}, 0\n",
    "for cap in train_corpus:\n",
    "    tokens = nltk.word_tokenize(cap.lower())\n",
    "    total_len += len(tokens)\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            vocab[w] += 1\n",
    "        except:\n",
    "            vocab[w] = 1\n",
    "\n",
    "print('Avg. count of words per caption:', total_len/len(train_corpus))\n",
    "print('Count of unique words: ', len(vocab))\n",
    "\n",
    "to_del = []\n",
    "for w in vocab.keys():\n",
    "    if not w in wordvectors:\n",
    "        to_del.append(w)\n",
    "        print('missing word: {}'.format(w))\n",
    "\n",
    "print('count of missing words: ', len(to_del))\n",
    "        \n",
    "for w in to_del:\n",
    "    del vocab[w]\n",
    "        \n",
    "idx2word = {idx: word for idx, word in enumerate(['<eos>', '<unk>'] + list(vocab.keys()))}\n",
    "word2idx = {word: idx for idx, word in enumerate(['<eos>', '<unk>'] + list(vocab.keys()))}\n",
    "EOS, UNK = 0, 1\n",
    "\n",
    "print(len(vocab), len(idx2word), len(word2idx))\n",
    "\n",
    "word_embeddings = np.zeros((len(idx2word), 300))\n",
    "for idx, word in idx2word.items():\n",
    "    if idx == EOS:\n",
    "        word_embeddings[idx] = wordvectors['eos']\n",
    "    elif idx == UNK:\n",
    "        word_embeddings[idx] = wordvectors['unk']\n",
    "    else:\n",
    "        word_embeddings[idx] = wordvectors[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine POS-tagging vocabulary from train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words per tag:\n",
      " DT:\t18\n",
      " NN:\t1669\n",
      " VBG:\t482\n",
      " IN:\t94\n",
      " RP:\t25\n",
      " .:\t3\n",
      " VBZ:\t454\n",
      " CD:\t18\n",
      " JJ:\t629\n",
      " ,:\t1\n",
      " RB:\t252\n",
      " CC:\t11\n",
      " NNS:\t582\n",
      " PRP:\t18\n",
      " VBN:\t207\n",
      " VBP:\t346\n",
      " WDT:\t5\n",
      " TO:\t1\n",
      " VB:\t465\n",
      " PRP$:\t9\n",
      " VBD:\t285\n",
      " WRB:\t6\n",
      " POS:\t4\n",
      " MD:\t10\n",
      " EX:\t1\n",
      " WP:\t4\n",
      " ::\t3\n",
      " RBR:\t11\n",
      " FW:\t7\n",
      " NNP:\t8\n",
      " JJR:\t18\n",
      " (:\t2\n",
      " ):\t2\n",
      " PDT:\t5\n",
      " JJS:\t8\n",
      " #:\t1\n",
      " SYM:\t2\n",
      " '':\t1\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "pos_vocab = {}\n",
    "pos_unique_words = {}\n",
    "for cap in train_corpus:\n",
    "    for tag in nltk.pos_tag(nltk.word_tokenize(cap.lower())):\n",
    "        try:\n",
    "            pos_vocab[tag[1]] += 1\n",
    "            try: \n",
    "                pos_unique_words[tag[1]][tag[0]] += 1\n",
    "            except:\n",
    "                pos_unique_words[tag[1]][tag[0]] = 1\n",
    "        except:\n",
    "            pos_vocab[tag[1]] = 1\n",
    "            pos_unique_words[tag[1]] = {tag[0]: 1}\n",
    "\n",
    "print('Unique words per tag:')\n",
    "print('\\n'.join([f' {k}:\\t{len(words)}' for k, words in pos_unique_words.items()]))\n",
    "            \n",
    "idx2pos = {idx: tag for idx, tag in enumerate(['eos', 'unk'] + list(pos_vocab.keys()))}\n",
    "pos2idx = {tag: idx for idx, tag in enumerate(['eos', 'unk'] + list(pos_vocab.keys()))}\n",
    "EOS, UNK = 0, 1\n",
    "print(len(idx2pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Universal POS-tagging from train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/jeperez/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words per universal tag:\n",
      " DET:\t27\n",
      " NOUN:\t2199\n",
      " VERB:\t1780\n",
      " ADP:\t94\n",
      " PRT:\t30\n",
      " .:\t13\n",
      " NUM:\t18\n",
      " ADJ:\t651\n",
      " ADV:\t265\n",
      " CONJ:\t11\n",
      " PRON:\t30\n",
      " X:\t9\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "upos_vocab = {}\n",
    "upos_unique_words = {}\n",
    "for cap in train_corpus:\n",
    "    for tag in nltk.pos_tag(nltk.word_tokenize(cap.lower()), tagset='universal'):\n",
    "        try:\n",
    "            upos_vocab[tag[1]] += 1\n",
    "            try: \n",
    "                upos_unique_words[tag[1]][tag[0]] += 1\n",
    "            except:\n",
    "                upos_unique_words[tag[1]][tag[0]] = 1\n",
    "        except:\n",
    "            upos_vocab[tag[1]] = 1\n",
    "            upos_unique_words[tag[1]] = {tag[0]: 1}\n",
    "\n",
    "print('Unique words per universal tag:')\n",
    "print('\\n'.join([f' {k}:\\t{len(words)}' for k, words in upos_unique_words.items()]))\n",
    "            \n",
    "idx2upos = {idx: word for idx, word in enumerate(['eos', 'unk'] + list(upos_vocab.keys()))}\n",
    "upos2idx = {word: idx for idx, word in enumerate(['eos', 'unk'] + list(upos_vocab.keys()))}\n",
    "print(len(idx2upos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ground-truth references files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/Charades_v1_val_references.txt', 'w') as f:\n",
    "    for vidx, cap in zip(valid_vidxs, valid_corpus):\n",
    "        f.write('{}\\t{}\\n'.format(vidx, cap.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate corpus.pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_corpus_widxs = [[word2idx[w] if w in vocab else UNK for w in nltk.word_tokenize(cap.lower())] + [EOS] for cap in train_corpus]\n",
    "valid_corpus_widxs = [[word2idx[w] if w in vocab else UNK for w in nltk.word_tokenize(cap.lower())] + [EOS] for cap in valid_corpus]\n",
    "test_corpus_widxs = [[word2idx[w] if w in vocab else UNK for w in nltk.word_tokenize(cap.lower())] + [EOS] for cap in test_corpus]\n",
    "\n",
    "train_corpus_pidxs = [[pos2idx[w[1]] if w[1] in pos_vocab else UNK for w in nltk.pos_tag(nltk.word_tokenize(cap.lower()))] + [EOS] for cap in train_corpus]\n",
    "valid_corpus_pidxs = [[pos2idx[w[1]] if w[1] in pos_vocab else UNK for w in nltk.pos_tag(nltk.word_tokenize(cap.lower()))] + [EOS] for cap in valid_corpus]\n",
    "test_corpus_pidxs = [[pos2idx[w[1]] if w[1] in pos_vocab else UNK for w in nltk.pos_tag(nltk.word_tokenize(cap.lower()))] + [EOS] for cap in test_corpus]\n",
    "\n",
    "assert len(train_corpus_widxs) == len(train_vidxs) and len(train_vidxs) == len(train_corpus_pidxs) and len(train_vidxs) == len(train_corpus), f'{len(train_vidxs)}, {len(train_corpus_widxs)}, {len(train_corpus_pidxs)}, {len(train_corpus)}'\n",
    "assert len(valid_corpus_widxs) == len(valid_vidxs) and len(valid_vidxs) == len(valid_corpus_pidxs) and len(valid_vidxs) == len(valid_corpus), f'{len(valid_vidxs)}, {len(valid_corpus_widxs)}, {len(valid_corpus_pidxs)}, {len(valid_corpus)}'\n",
    "assert len(test_corpus_widxs) == len(test_vidxs) and len(test_vidxs) == len(test_corpus_pidxs) and len(test_vidxs) == len(test_corpus), f'{len(test_vidxs)}, {len(test_corpus_widxs)}, {len(test_corpus_pidxs)}, {len(test_corpus)}'\n",
    "\n",
    "train_data = [train_corpus_widxs, train_vidxs, train_corpus_pidxs, train_corpus]\n",
    "valid_data = [valid_corpus_widxs, valid_vidxs, valid_corpus_pidxs, valid_corpus]\n",
    "test_data = [test_corpus_widxs, test_vidxs, test_corpus_pidxs, test_corpus]\n",
    "\n",
    "with open('../../../data/LSDMC/charades_v1_corpus_pos.pkl', 'wb') as outfile:\n",
    "    pickle.dump([train_data, valid_data, test_data, vocab, idx2word, word_embeddings, idx2pos], outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
